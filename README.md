# ðŸŒ± Progetto-Carbon

**Esercizi di Machine Learning e Deep Learning** realizzati nellâ€™ambito del corso di **Rigenerazione**.

Questo repository raccoglie una serie di esempi, notebook e modelli sviluppati per comprendere e applicare tecniche di apprendimento automatico e profondo, con un focus su:

- ðŸ“Š Preprocessing e analisi dei dati
- ðŸ§  Modelli di classificazione e regressione
- ðŸ” Tecniche di ottimizzazione e validazione
- ðŸ¤– Reti neurali semplici (MLP), CNN e RNN
- ðŸ§ª Applicazioni a problemi reali o simulati legati alla rigenerazione urbana e ambientale

---

## ðŸ“ Struttura del progetto

- `notebooks/` â€“ Notebook interattivi divisi per tema ed esercizio
- `data/` â€“ Dati utilizzati (in formato CSV, immagini o JSON)
- `models/` â€“ Architetture salvate e pesi pre-addestrati (opzionale)
- `utils/` â€“ Funzioni comuni di supporto (metriche, visualizzazione, ecc.)

---

## ðŸš€ Obiettivi formativi

Il progetto ha lo scopo di:
- Allenare le competenze pratiche di ML/DL
- Favorire lâ€™apprendimento sperimentale attraverso esempi concreti
- Collegare lâ€™AI a contesti di rigenerazione sostenibile

---

## ðŸ§  Requisiti principali

- Python 3.9+
- `numpy`, `pandas`, `matplotlib`
- `scikit-learn`, `tensorflow` o `pytorch`
- (opzionale) `jupyterlab` o Google Colab

---

## ðŸ§  Esercizi di NLP (Natural Language Processing)

Questa sezione contiene esercizi introduttivi sul trattamento automatico del linguaggio naturale con **spaCy**, applicati alla lingua italiana.

Ogni esercizio Ã¨ focalizzato su un singolo concetto fondamentale del NLP, utile per costruire pipeline linguistiche, motori di ricerca semantici, e classificatori testuali.

### ðŸ“˜ Esercizi contenuti:

#### ðŸ“Œ 1. TOKENIZATION â€” Suddividere il testo in unitÃ  minime
Suddivide un testo in parole, segni di punteggiatura e simboli, detti *token*.

#### ðŸ“Œ 2. POS TAGGING â€” Etichettatura grammaticale
Assegna a ogni parola la sua **categoria grammaticale** (nome, verbo, aggettivo, ecc.).

#### ðŸ“Œ 3. NER â€” Named Entity Recognition
Riconosce le **entitÃ  nominate** nel testo, come persone, cittÃ , date, organizzazioni.

#### ðŸ“Œ 4. LEMMATIZATION â€” Forma base della parola
Riconduce ogni parola alla sua **forma base (lemma)**: ad es. "correvano" â†’ "correre".

#### ðŸ“Œ 5. DEPENDENCY PARSING â€” Struttura sintattica
Analizza **le relazioni grammaticali** tra parole, come soggetto-verbo-oggetto.

#### ðŸ“Œ 6. VOCABULARY â€” Costruzione del dizionario dei lemmi
Estrae tutti i lemmi univoci presenti in un testo, e ne calcola la frequenza.

#### ðŸ“Œ 7. STOP WORD FILTERING â€” Rimozione parole vuote
Filtra parole comuni che non aggiungono significato semantico (es. "il", "di", "e").

#### ðŸ“Œ 8. VISUALIZZAZIONI â€” Con displacy
Visualizza:
- le **relazioni sintattiche** tra parole (`style="dep"`)
- le **entitÃ  nominate** evidenziate nel testo (`style="ent"`)

---

Tutti gli esercizi sono implementati in Python e pensati per essere eseguiti in **Google Colab** o **Jupyter Notebook**, con esempi chiari e commentati.

ðŸ“‚ Percorso: `notebooks/nlp/`


---

## ðŸ“Œ Note

Il progetto Ã¨ in continuo aggiornamento, e ogni esercizio Ã¨ pensato per essere auto-contenuto e ben documentato.

> Per domande, idee o contributi, sentiti libero di aprire una issue o inviare una pull request!

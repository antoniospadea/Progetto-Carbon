# ðŸŒ± Progetto-Carbon

**Esercizi di Machine Learning e Deep Learning** realizzati nellâ€™ambito del corso di **Rigenerazione**.

Questo repository raccoglie una serie di esempi, notebook e modelli sviluppati per comprendere e applicare tecniche di apprendimento automatico e profondo, con un focus su:

- ðŸ“Š Preprocessing e analisi dei dati
- ðŸ§  Modelli di classificazione e regressione
- ðŸ” Tecniche di ottimizzazione e validazione
- ðŸ¤– Reti neurali semplici (MLP), CNN e RNN
- ðŸ§ª Applicazioni a problemi reali o simulati legati alla rigenerazione urbana e ambientale

---

## ðŸ“ Struttura del progetto

- `notebooks/` â€“ Notebook interattivi divisi per tema ed esercizio
- `data/` â€“ Dati utilizzati (in formato CSV, immagini o JSON)
- `models/` â€“ Architetture salvate e pesi pre-addestrati (opzionale)
- `utils/` â€“ Funzioni comuni di supporto (metriche, visualizzazione, ecc.)

---

## ðŸš€ Obiettivi formativi

Il progetto ha lo scopo di:
- Allenare le competenze pratiche di ML/DL
- Favorire lâ€™apprendimento sperimentale attraverso esempi concreti
- Collegare lâ€™AI a contesti di rigenerazione sostenibile

---

## ðŸ§  Requisiti principali

- Python 3.9+
- `numpy`, `pandas`, `matplotlib`
- `scikit-learn`, `tensorflow` o `pytorch`
- (opzionale) `jupyterlab` o Google Colab

---

## ðŸ§  Esercizi di NLP (Natural Language Processing)

Questa sezione contiene esercizi introduttivi sul trattamento automatico del linguaggio naturale con **spaCy**, applicati alla lingua italiana.

Ogni esercizio Ã¨ focalizzato su un singolo concetto fondamentale del NLP, utile per costruire pipeline linguistiche, motori di ricerca semantici, e classificatori testuali.

### ðŸ§ª Esempio guidato: Analisi NLP di una frase

Per comprendere meglio le operazioni NLP affrontate negli esercizi, utilizziamo una semplice frase in italiano:

> **"Il gatto salta sul tavolo e beve il latte."**

Vediamo passo per passo cosa accade durante ogni fase dellâ€™elaborazione linguistica automatica:

---

ðŸ“Œ **1. Tokenization**  
Il testo viene suddiviso in unitÃ  minime, chiamate *token*:  
`[Il, gatto, salta, sul, tavolo, e, beve, il, latte, .]`

---

ðŸ“Œ **2. POS Tagging**  
A ogni token viene assegnata una **categoria grammaticale**:  
- `gatto` â†’ NOUN (nome)  
- `salta` â†’ VERB (verbo)  
- `sul` â†’ ADP (preposizione articolata)  
- `latte` â†’ NOUN

---

ðŸ“Œ **3. Named Entity Recognition (NER)**  
In questa frase non sono presenti entitÃ  nominate (come persone o luoghi), quindi **nessuna entitÃ  viene riconosciuta**.  
In frasi piÃ¹ complesse, spaCy puÃ² identificare:  
`Luca Bianchi` â†’ `PER` (persona), `Roma` â†’ `LOC` (luogo), ecc.

---

ðŸ“Œ **4. Lemmatization**  
Ogni parola viene trasformata nella sua forma base (*lemma*):  
- `salta` â†’ `saltare`  
- `beve` â†’ `bere`  
- `gatto` â†’ `gatto`

---

ðŸ“Œ **5. Dependency Parsing**  
Analizziamo **la struttura grammaticale**:  
- `gatto` Ã¨ il soggetto (`nsubj`) del verbo `salta`  
- `latte` Ã¨ lâ€™oggetto (`obj`) del verbo `beve`  
- `tavolo` Ã¨ il complemento di luogo (`obl`)

---

ðŸ“Œ **6. Vocabulary Construction**  
Costruiamo un dizionario dei lemmi presenti nel testo (escludendo punteggiatura e parole irrilevanti):  
`{"gatto": 1, "saltare": 1, "tavolo": 1, "bere": 1, "latte": 1}`

---

ðŸ“Œ **7. Stop Word Filtering**  
Filtriamo parole poco informative come articoli e congiunzioni:  
**Rimangono:** `gatto`, `salta`, `tavolo`, `beve`, `latte`

---

ðŸ“Œ **8. Visualizzazioni con displacy**  
Attraverso grafici interattivi visualizziamo:  
- **Le relazioni sintattiche**, con archi che collegano soggetto-verbo-oggetto
- **Le entitÃ  nominate** (se presenti), evidenziate nel testo

---

Tutti gli esercizi sono implementati in Python e pensati per essere eseguiti in **Google Colab** o **Jupyter Notebook**, con esempi chiari e commentati.

ðŸ“‚ Percorso: `notebooks/nlp/`


---

## ðŸ“Œ Note

Il progetto Ã¨ in continuo aggiornamento, e ogni esercizio Ã¨ pensato per essere auto-contenuto e ben documentato.

> Per domande, idee o contributi, sentiti libero di aprire una issue o inviare una pull request!
